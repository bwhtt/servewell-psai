# The PSAI Framework

## What We Measure

The Public Servant Appreciation Index measures how well states support and value their public workforce through five essential dimensions. Each dimension captures a different aspect of what it means to truly appreciate public servantsâ€”from fair pay to professional development to public recognition.

---

## The Five Dimensions

### 1. Competitive Compensation (30% of total score)

**What it measures**: Whether public servants are paid fairly compared to private-sector workers and whether total compensation (salary + benefits + leave) makes public service financially sustainable.

**Why it matters**: You can't expect people to serve their communities if they can't afford rent, pay off student loans, or plan for retirement. Competitive compensation isn't about getting richâ€”it's about making public service a viable career choice rather than a financial sacrifice.

**What we evaluate**:
- Salary competitiveness vs. private sector (adjusted for cost of living)
- Benefits quality (pension, health insurance, retirement plans)
- Paid leave policies (vacation, sick time, personal days, holidays)
- Additional perks (tuition reimbursement, student loan forgiveness, transit benefits)

---

### 2. Workforce Health (28% of total score)

**What it measures**: Whether states can attract and keep talented public servants, or whether positions sit vacant and employees leave quickly.

**Why it matters**: High vacancy rates and constant turnover signal deeper problemsâ€”burnout, poor working conditions, inadequate support. When a quarter of corrections officer positions sit empty or teachers leave after two years, it's a crisis for both employees and the communities they serve. Healthy workforces deliver better services.

**What we evaluate**:
- Employee retention rates (how many stay year over year)
- Critical vacancy rates (unfilled positions in key sectors like education, healthcare, social services)
- Average tenure (how long employees build careers in public service)

---

### 3. Public Perception & Trust (22% of total score)

**What it measures**: Whether citizens trust state government and whether public servants are visibly recognized and celebrated.

**Why it matters**: Public servants work better when they feel valuedâ€”not just by their managers, but by the communities they serve. When only 35% of citizens trust state government, it undermines employee morale and makes recruitment harder. Recognition events and public appreciation signal that this work matters.

**What we evaluate**:
- Public trust in state government (polling data)
- Frequency and visibility of recognition events (awards, proclamations, ceremonies)
- Statewide celebration infrastructure (Employee of the Year programs, appreciation weeks, public spotlights)

---

### 4. Investment in People (15% of total score)

**What it measures**: Whether states invest in employee growth, skills development, and modern toolsâ€”or expect people to succeed without support.

**Why it matters**: The best compensation means little if employees don't have the training, technology, or development opportunities to do their jobs well and advance their careers. States that invest in their people signal: "We want you to grow here, not just survive."

**What we evaluate**:
- Training budgets (per-employee spending on skill development)
- Professional development access (leadership programs, certifications, mentoring)
- Technology modernization (modern HR systems, productivity tools, infrastructure)

---

### 5. Recognition Infrastructure (5% of total score)

**What it measures**: Whether states have formal, visible systems to celebrate outstanding public servants.

**Why it matters**: Everyone wants to feel seen and appreciated. Recognition programsâ€”from service milestone awards to Employee of the Year ceremoniesâ€”create culture. They signal to current employees "your work matters" and to potential recruits "this is a place that values people." While important, recognition without fair pay rings hollow, hence the lower weight.

**What we evaluate**:
- Stories on Humans of Public Service (HOPS) platform (public celebration of exemplary employees)
- Formal recognition programs (length-of-service awards, excellence programs, innovation awards)
- Official observances (Public Service Recognition Week proclamations, statewide events)

---

## How Dimensions Combine Into a Final Score

Each dimension receives a score from 0-100 based on performance across its components. These dimension scores are then weighted and combined into a final composite score:

**Composite Score = (0.30 Ã— Compensation) + (0.28 Ã— Workforce Health) + (0.22 Ã— Public Perception) + (0.15 Ã— Investment) + (0.05 Ã— Recognition)**

### Why These Weights?

The weights reflect relative importance for making public service sustainable:

**Compensation (30%)**: Foundationâ€”people can't serve if they can't pay bills  
**Workforce Health (28%)**: Outcomeâ€”healthy workforces signal everything else is working  
**Public Perception (22%)**: Environmentâ€”trust and appreciation affect morale and recruitment  
**Investment (15%)**: Growthâ€”training and tools help people succeed  
**Recognition (5%)**: Cultureâ€”important, but meaningless without the other four

---

## Three Performance Tiers

Final scores are categorized into three tiers based on fixed thresholds:

**ðŸŸ¢ Leading (75-100 points)**  
States in this tier have built comprehensive support systems for public servants. They offer competitive pay, maintain healthy workforces, invest in development, and create cultures of appreciation. These states make public service financially sustainable and professionally rewarding.

**ðŸŸ¡ Developing (50-74 points)**  
States in this tier have solid foundations but significant room to grow. They typically excel in one or two dimensions while lagging in others. With targeted improvementsâ€”publishing training data, expanding recognition programs, addressing critical vacanciesâ€”these states could reach Leading status.

**ðŸ”´ Emerging (0-49 points)**  
States in this tier face fundamental challenges in supporting public servants. Multiple dimensions show low scores, indicating systemic gaps in compensation, workforce stability, or investment. These states need comprehensive reforms to make public service viable.

**Current reality**: All five states initially assessed (Maryland, Massachusetts, Virginia, Washington, North Carolina) scored in the "Developing" tier (61-68 points), indicating nationwide room for improvement.

---

## What This Framework Doesn't Measure

The PSAI focuses on quantifiable, comparable metrics across states. Important factors we don't currently capture include:

- **Workplace culture** (leadership quality, psychological safety, work-life balance)
- **Mission alignment** (whether work feels meaningful)
- **Career advancement** (promotion pathways, mobility opportunities)
- **Geographic differences** (urban vs. rural working conditions)
- **Job security** (protection from political interference or arbitrary termination)
- **Workload** (understaffing leading to burnout even with good pay)

These matter deeply but are harder to measure consistently across states. We welcome suggestions for adding dimensions that maintain methodological rigor.

---

## How the Framework Evolved

The PSAI didn't emerge fully formedâ€”it improved through real-world testing across five states. Each version addressed challenges we discovered:

- **v1.0**: Basic framework established (Maryland pilot)
- **v2.0**: Clarified calculation methods, added data quality standards
- **v2.1**: Protected formula integrity, added minimum search requirements
- **v2.2**: Implemented reality checks and error prevention (current version)

**[Read the full evolution story â†’](link-to-framework-evolution-summary)**

---

## Framework Transparency

Every element of this frameworkâ€”dimension definitions, component weights, scoring formulas, quality controlsâ€”is documented and available for review:

**[Complete Framework Documentation v2.2](link-to-full-framework)**  
**[Framework Change History](link-to-change-history)**  
**[GitHub Repository](link-to-github)** â€“ View all formulas, prompts, and data

If you believe elements of this framework should change, **[we want to hear from you](link-to-feedback)**.

---

**[View State Reports â†’](#) | [Learn About Methodology â†’](#) | [Get Involved â†’](#)**
-e 
---

# How the Framework Evolved

The PSAI framework didn't emerge fully formedâ€”it improved through real-world testing across five diverse states. Each version addressed specific challenges we discovered, making the methodology more reliable and consistent.

---

## The Journey: v1.0 â†’ v2.2

### v1.0 - Maryland Pilot (December 2024)
**What we built**: Basic five-dimension framework with fixed weights

**What we learned**: The core structure worked, but we needed clearer guidance on specific calculations. Questions emerged: Should we use weighted averages or medians for salary comparisons? How do we count recognition events fairly? What do we do when training data isn't published?

---

### v2.0 - Clarity & Consistency (December 2024)
**What we added**:
- **Salary methodology clarification**: Use median occupational ratios (more resistant to outliers)
- **Recognition event weighting**: Annual ceremonies count more (1.0) than monthly newsletters (0.5)
- **Transparency standard**: Mark missing data as "DATA NOT PUBLISHED" rather than estimatingâ€”creates incentive for government transparency
- **Data quality flags**: Label every data point as Verified, Estimated, or Data Not Published

**Why it mattered**: Clear rules meant every state could be assessed the same way.

---

### v2.1 - Formula Protection (December 2024)
**The problem**: Virginia's analysis modified formula weights, making scores incomparable to Maryland

**What we added**:
- **Formula lock**: Component weights are fixed and non-negotiable across all states
- **Verification checklist**: Analysts must confirm all six formulas match the framework exactly
- **Minimum search times**: Prevents rushing through data collection (e.g., 2.5 hours minimum for recognition events)

**Why it mattered**: Comparison only works if everyone uses identical methodology. We prioritized consistency over optimizing any single state's score.

---

### v2.2 - Error Prevention (December 2024)
**The problem**: Massachusetts initially showed $49,598 median salary (making them look like the worst-paying state). Reality: $73,645 median (making them one of the best). This 5-point error wasted hours of analysis.

**What we added**:
- **Reality checks**: Salary data must pass five validation tests before analysis proceeds
- **Approval checkpoints**: Reviewer must approve salary data before analyst continues
- **Expected ranges by state type**: High COL + strong unions should show $60-85K median; anything outside triggers investigation
- **Lessons learned documentation**: Every error gets documented so future analysts avoid the same mistakes

**Why it mattered**: Catch errors in 30 minutes instead of discovering them after 5 hours of work. Prevention beats correction.

---

## Core Principles That Emerged

Through this evolution, five principles became clear:

**1. Consistency Over Optimization**  
Fixed formulas across all states matter more than making any single state look better.

**2. Transparency Over Estimation**  
Mark missing data openly rather than guessing. Creates accountability for government transparency.

**3. Verification Over Speed**  
Reality checks and approval points prevent massive rework later.

**4. Median Over Weighted**  
Median ratios better represent typical employee experience (not skewed by occupational mix).

**5. Documentation Over Memory**  
Every lesson learned gets written down so the next analyst benefits from past mistakes.

---

## What Stayed Constant

Despite three major revisions, the core structure never changed:

âœ… Five dimensions (Compensation, Workforce Health, Public Perception, Investment, Recognition)  
âœ… Dimension weights (30%, 28%, 22%, 15%, 5%)  
âœ… 0-100 scoring scale  
âœ… Three performance tiers (Leading, Developing, Emerging)  
âœ… Component-based approach within each dimension

**Why**: The fundamental framework was sound from the start. We refined execution, not design.

---

## Current Status: v2.2 (Stable & Mature)

The framework has been tested across five states with diverse characteristics:
- Strong union states (MA, WA) and right-to-work states (VA, NC)
- High cost-of-living (MA, WA) and moderate (MD, VA, NC)
- Tech-heavy economies (WA, MA) and government-focused (MD, VA)

**Results**:
- 100% formula compliance across all states âœ…
- Zero major data errors after implementing v2.2 checkpoints âœ…
- All scores directly comparable âœ…
- Methodology is replicable and transparent âœ…

---

## For Deeper Detail

This summary covers the essential evolution. For complete documentation:
- **[Full Framework Change History](link-to-full-doc)**: Version-by-version details with exact formula changes
- **[Quality Control Procedures](link-to-full-doc)**: Every checkpoint, reality check, and verification step
- **[Framework v2.2 Documentation](link-to-full-doc)**: Complete methodology with all formulas

---

*Last updated: December 31, 2025 | Framework version: 2.2*
